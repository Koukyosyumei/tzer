{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec3e7da2-5ce5-423f-b3df-be31b840dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tvm.contrib.download import download_testdata\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddf464c8-a8eb-40a5-aa6d-a0f24ca4200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "model = getattr(torchvision.models, model_name)(pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [1, 3, 224, 224]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3ea7edc-9ac4-46af-9ae4-71a84973ada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.maxpool(model.bn1(model.conv1(input_data))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc616c3f-cb56-4fd9-a120-d6cec414a1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1(model.maxpool(model.bn1(model.conv1(input_data)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cef7a623-ef61-4e33-a992-cd019c15bbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 28, 28])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer2(model.layer1(model.maxpool(model.bn1(model.conv1(input_data))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46be5dfc-3a9d-4d79-9b8f-c739876a040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 14, 14])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer3(model.layer2(model.layer1(model.maxpool(model.bn1(model.conv1(input_data)))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fb5481a0-cb2a-4888-8e10-47228146c77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 7, 7])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer4(model.layer3(model.layer2(model.layer1(model.maxpool(model.bn1(model.conv1(input_data))))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5da51d35-4219-4109-b79f-a5ea5b8e8847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.avgpool(model.layer4(model.layer3(model.layer2(model.layer1(model.maxpool(model.bn1(model.conv1(input_data)))))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c238488-af50-4cce-a20e-9a66c9423acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a24b99e8-8671-428d-beba-312b88015322",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 224\n",
    "\n",
    "img_url = (\n",
    "    \"https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/detection/street_small.jpg\"\n",
    ")\n",
    "img_path = download_testdata(img_url, \"test_street_small.jpg\", module=\"data\")\n",
    "\n",
    "img = cv2.imread(img_path).astype(\"float32\")\n",
    "img = cv2.resize(img, (in_size, in_size))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.transpose(img / 255.0, [2, 0, 1])\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d36f610-cd12-4f9c-861a-253f68cda080",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, input_shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6758a284-4316-4277-9357-9f5617ce5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "with tvm.transform.PassContext(opt_level=1):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "model = graph_executor.GraphModule(lib[\"default\"](tvm.device(target, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f0c20ba-cc5e-44cf-a306-1250c972bb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.contrib.graph_executor.GraphModule at 0xff2a3876d3c0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6ba74aa9-8efa-4063-915b-ea40134aad39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': Var(input0, ty=TensorType([1, 3, 224, 224], float32)),\n",
       " '1': Var(aten::_convolution_0.weight, ty=TensorType([64, 3, 7, 7], float32)),\n",
       " '2': Var(aten::batch_norm_0.weight, ty=TensorType([64], float32)),\n",
       " '3': Var(aten::batch_norm_0.bias, ty=TensorType([64], float32)),\n",
       " '4': Var(aten::batch_norm_0.running_mean, ty=TensorType([64], float32)),\n",
       " '5': Var(aten::batch_norm_0.running_var, ty=TensorType([64], float32)),\n",
       " '6': Var(aten::_convolution_1.weight, ty=TensorType([64, 64, 3, 3], float32)),\n",
       " '7': Var(aten::batch_norm_1.weight, ty=TensorType([64], float32)),\n",
       " '8': Var(aten::batch_norm_1.bias, ty=TensorType([64], float32)),\n",
       " '9': Var(aten::batch_norm_1.running_mean, ty=TensorType([64], float32)),\n",
       " '10': Var(aten::batch_norm_1.running_var, ty=TensorType([64], float32)),\n",
       " '11': Var(aten::_convolution_2.weight, ty=TensorType([64, 64, 3, 3], float32)),\n",
       " '12': Var(aten::batch_norm_2.weight, ty=TensorType([64], float32)),\n",
       " '13': Var(aten::batch_norm_2.bias, ty=TensorType([64], float32)),\n",
       " '14': Var(aten::batch_norm_2.running_mean, ty=TensorType([64], float32)),\n",
       " '15': Var(aten::batch_norm_2.running_var, ty=TensorType([64], float32)),\n",
       " '16': Var(aten::_convolution_3.weight, ty=TensorType([64, 64, 3, 3], float32)),\n",
       " '17': Var(aten::batch_norm_3.weight, ty=TensorType([64], float32)),\n",
       " '18': Var(aten::batch_norm_3.bias, ty=TensorType([64], float32)),\n",
       " '19': Var(aten::batch_norm_3.running_mean, ty=TensorType([64], float32)),\n",
       " '20': Var(aten::batch_norm_3.running_var, ty=TensorType([64], float32)),\n",
       " '21': Var(aten::_convolution_4.weight, ty=TensorType([64, 64, 3, 3], float32)),\n",
       " '22': Var(aten::batch_norm_4.weight, ty=TensorType([64], float32)),\n",
       " '23': Var(aten::batch_norm_4.bias, ty=TensorType([64], float32)),\n",
       " '24': Var(aten::batch_norm_4.running_mean, ty=TensorType([64], float32)),\n",
       " '25': Var(aten::batch_norm_4.running_var, ty=TensorType([64], float32)),\n",
       " '26': Var(aten::_convolution_5.weight, ty=TensorType([128, 64, 3, 3], float32)),\n",
       " '27': Var(aten::batch_norm_5.weight, ty=TensorType([128], float32)),\n",
       " '28': Var(aten::batch_norm_5.bias, ty=TensorType([128], float32)),\n",
       " '29': Var(aten::batch_norm_5.running_mean, ty=TensorType([128], float32)),\n",
       " '30': Var(aten::batch_norm_5.running_var, ty=TensorType([128], float32)),\n",
       " '31': Var(aten::_convolution_6.weight, ty=TensorType([128, 128, 3, 3], float32)),\n",
       " '32': Var(aten::batch_norm_6.weight, ty=TensorType([128], float32)),\n",
       " '33': Var(aten::batch_norm_6.bias, ty=TensorType([128], float32)),\n",
       " '34': Var(aten::batch_norm_6.running_mean, ty=TensorType([128], float32)),\n",
       " '35': Var(aten::batch_norm_6.running_var, ty=TensorType([128], float32)),\n",
       " '36': Var(aten::_convolution_7.weight, ty=TensorType([128, 64, 1, 1], float32)),\n",
       " '37': Var(aten::batch_norm_7.weight, ty=TensorType([128], float32)),\n",
       " '38': Var(aten::batch_norm_7.bias, ty=TensorType([128], float32)),\n",
       " '39': Var(aten::batch_norm_7.running_mean, ty=TensorType([128], float32)),\n",
       " '40': Var(aten::batch_norm_7.running_var, ty=TensorType([128], float32)),\n",
       " '41': Var(aten::_convolution_8.weight, ty=TensorType([128, 128, 3, 3], float32)),\n",
       " '42': Var(aten::batch_norm_8.weight, ty=TensorType([128], float32)),\n",
       " '43': Var(aten::batch_norm_8.bias, ty=TensorType([128], float32)),\n",
       " '44': Var(aten::batch_norm_8.running_mean, ty=TensorType([128], float32)),\n",
       " '45': Var(aten::batch_norm_8.running_var, ty=TensorType([128], float32)),\n",
       " '46': Var(aten::_convolution_9.weight, ty=TensorType([128, 128, 3, 3], float32)),\n",
       " '47': Var(aten::batch_norm_9.weight, ty=TensorType([128], float32)),\n",
       " '48': Var(aten::batch_norm_9.bias, ty=TensorType([128], float32)),\n",
       " '49': Var(aten::batch_norm_9.running_mean, ty=TensorType([128], float32)),\n",
       " '50': Var(aten::batch_norm_9.running_var, ty=TensorType([128], float32)),\n",
       " '51': Var(aten::_convolution_10.weight, ty=TensorType([256, 128, 3, 3], float32)),\n",
       " '52': Var(aten::batch_norm_10.weight, ty=TensorType([256], float32)),\n",
       " '53': Var(aten::batch_norm_10.bias, ty=TensorType([256], float32)),\n",
       " '54': Var(aten::batch_norm_10.running_mean, ty=TensorType([256], float32)),\n",
       " '55': Var(aten::batch_norm_10.running_var, ty=TensorType([256], float32)),\n",
       " '56': Var(aten::_convolution_11.weight, ty=TensorType([256, 256, 3, 3], float32)),\n",
       " '57': Var(aten::batch_norm_11.weight, ty=TensorType([256], float32)),\n",
       " '58': Var(aten::batch_norm_11.bias, ty=TensorType([256], float32)),\n",
       " '59': Var(aten::batch_norm_11.running_mean, ty=TensorType([256], float32)),\n",
       " '60': Var(aten::batch_norm_11.running_var, ty=TensorType([256], float32)),\n",
       " '61': Var(aten::_convolution_12.weight, ty=TensorType([256, 128, 1, 1], float32)),\n",
       " '62': Var(aten::batch_norm_12.weight, ty=TensorType([256], float32)),\n",
       " '63': Var(aten::batch_norm_12.bias, ty=TensorType([256], float32)),\n",
       " '64': Var(aten::batch_norm_12.running_mean, ty=TensorType([256], float32)),\n",
       " '65': Var(aten::batch_norm_12.running_var, ty=TensorType([256], float32)),\n",
       " '66': Var(aten::_convolution_13.weight, ty=TensorType([256, 256, 3, 3], float32)),\n",
       " '67': Var(aten::batch_norm_13.weight, ty=TensorType([256], float32)),\n",
       " '68': Var(aten::batch_norm_13.bias, ty=TensorType([256], float32)),\n",
       " '69': Var(aten::batch_norm_13.running_mean, ty=TensorType([256], float32)),\n",
       " '70': Var(aten::batch_norm_13.running_var, ty=TensorType([256], float32)),\n",
       " '71': Var(aten::_convolution_14.weight, ty=TensorType([256, 256, 3, 3], float32)),\n",
       " '72': Var(aten::batch_norm_14.weight, ty=TensorType([256], float32)),\n",
       " '73': Var(aten::batch_norm_14.bias, ty=TensorType([256], float32)),\n",
       " '74': Var(aten::batch_norm_14.running_mean, ty=TensorType([256], float32)),\n",
       " '75': Var(aten::batch_norm_14.running_var, ty=TensorType([256], float32)),\n",
       " '76': Var(aten::_convolution_15.weight, ty=TensorType([512, 256, 3, 3], float32)),\n",
       " '77': Var(aten::batch_norm_15.weight, ty=TensorType([512], float32)),\n",
       " '78': Var(aten::batch_norm_15.bias, ty=TensorType([512], float32)),\n",
       " '79': Var(aten::batch_norm_15.running_mean, ty=TensorType([512], float32)),\n",
       " '80': Var(aten::batch_norm_15.running_var, ty=TensorType([512], float32)),\n",
       " '81': Var(aten::_convolution_16.weight, ty=TensorType([512, 512, 3, 3], float32)),\n",
       " '82': Var(aten::batch_norm_16.weight, ty=TensorType([512], float32)),\n",
       " '83': Var(aten::batch_norm_16.bias, ty=TensorType([512], float32)),\n",
       " '84': Var(aten::batch_norm_16.running_mean, ty=TensorType([512], float32)),\n",
       " '85': Var(aten::batch_norm_16.running_var, ty=TensorType([512], float32)),\n",
       " '86': Var(aten::_convolution_17.weight, ty=TensorType([512, 256, 1, 1], float32)),\n",
       " '87': Var(aten::batch_norm_17.weight, ty=TensorType([512], float32)),\n",
       " '88': Var(aten::batch_norm_17.bias, ty=TensorType([512], float32)),\n",
       " '89': Var(aten::batch_norm_17.running_mean, ty=TensorType([512], float32)),\n",
       " '90': Var(aten::batch_norm_17.running_var, ty=TensorType([512], float32)),\n",
       " '91': Var(aten::_convolution_18.weight, ty=TensorType([512, 512, 3, 3], float32)),\n",
       " '92': Var(aten::batch_norm_18.weight, ty=TensorType([512], float32)),\n",
       " '93': Var(aten::batch_norm_18.bias, ty=TensorType([512], float32)),\n",
       " '94': Var(aten::batch_norm_18.running_mean, ty=TensorType([512], float32)),\n",
       " '95': Var(aten::batch_norm_18.running_var, ty=TensorType([512], float32)),\n",
       " '96': Var(aten::_convolution_19.weight, ty=TensorType([512, 512, 3, 3], float32)),\n",
       " '97': Var(aten::batch_norm_19.weight, ty=TensorType([512], float32)),\n",
       " '98': Var(aten::batch_norm_19.bias, ty=TensorType([512], float32)),\n",
       " '99': Var(aten::batch_norm_19.running_mean, ty=TensorType([512], float32)),\n",
       " '100': Var(aten::batch_norm_19.running_var, ty=TensorType([512], float32)),\n",
       " '101': Var(aten::linear_0.weight, ty=TensorType([1000, 512], float32)),\n",
       " '102': Var(aten::linear_0.bias, ty=TensorType([1000], float32))}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dict = {}\n",
    "for i, var in enumerate(mod[\"main\"].params):\n",
    "    layer_dict[str(i)] = var\n",
    "\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "effc63f8-ef2b-4335-b688-4a366c6155e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_func = mod[\"main\"]\n",
    "expr = main_func.body\n",
    "set_layers = set({})\n",
    "layers = []\n",
    "\n",
    "def traverse_expr(expr):\n",
    "    global set_layers, layers\n",
    "    if isinstance(expr, relay.expr.Call):\n",
    "        if expr.op.name == \"nn.conv2d\" or expr.op.name == \"nn.dense\":\n",
    "            if expr not in set_layers:\n",
    "                set_layers |= {expr}\n",
    "                layers.append(expr)\n",
    "        for arg in expr.args:\n",
    "            traverse_expr(arg)\n",
    "            \n",
    "    elif isinstance(expr, relay.expr.TupleGetItem):\n",
    "        for arg in expr.tuple_value.args:\n",
    "            traverse_expr(arg)\n",
    "\n",
    "traverse_expr(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a15b1bc4-19bd-4a98-9429-872658ce2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(layers) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3cc5262a-6552-47c0-9667-46341a34e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relay_layer_functions = [relay.Function(main_func.params, layer) for layer in layers]\n",
    "layer_mods = [tvm.IRModule.from_expr(rlf) for rlf in relay_layer_functions]\n",
    "layer_libs = []\n",
    "\n",
    "target = \"llvm\" #if self.device == \"cpu\" else \"cuda\"\n",
    "for lm in layer_mods:\n",
    "    with tvm.transform.PassContext(opt_level=1):\n",
    "        lib = relay.build(lm, target=target, params=params)\n",
    "        layer_libs.append(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b0d53f2a-8d7d-461f-97e0-fb2bebe4d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\" #if self.device == \"cpu\" else \"cuda\"\n",
    "layer_models = [graph_executor.GraphModule(lib[\"default\"](tvm.device(target, 0))) for lib in layer_libs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "be911608-71fe-45a6-8ee9-0c886f6db1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_output_list = []\n",
    "\n",
    "for tmp_model in layer_models:\n",
    "    tmp_model.set_input(\"input0\", tvm.nd.array(input_data))\n",
    "    tmp_model.run()\n",
    "    dummy_output_list.append(tmp_model.get_output(0).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "25b7a13a-8a6d-452d-9b09-b3729fcd0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "(1, 512, 7, 7)\n",
      "(1, 512, 7, 7)\n",
      "(1, 512, 7, 7)\n",
      "(1, 512, 7, 7)\n",
      "(1, 256, 14, 14)\n",
      "(1, 256, 14, 14)\n",
      "(1, 256, 14, 14)\n",
      "(1, 256, 14, 14)\n",
      "(1, 128, 28, 28)\n",
      "(1, 128, 28, 28)\n",
      "(1, 128, 28, 28)\n",
      "(1, 128, 28, 28)\n",
      "(1, 64, 56, 56)\n",
      "(1, 64, 56, 56)\n",
      "(1, 64, 56, 56)\n",
      "(1, 64, 56, 56)\n",
      "(1, 64, 112, 112)\n",
      "(1, 128, 28, 28)\n",
      "(1, 256, 14, 14)\n",
      "(1, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "for do in dummy_output_list:\n",
    "    print(do.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb312e4c-0fae-46fe-a48b-988040a59924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
